import os
import re
import streamlit as st
from langchain.llms import HuggingFaceEndpoint
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_openai import OpenAIEmbeddings
from langchain.agents import load_tools, initialize_agent, Tool
from langchain.memory import ConversationBufferMemory
import openai
from transformers import AutoTokenizer, pipeline
from google.cloud import translate_v2 as translate

os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = ''
os.environ['OPENAI_API_KEY'] = ''
HUGGINGFACEHUB_API_TOKEN = ""
os.environ["SERPER_API_KEY"] = ''
openai.api_key = ''
chromadb = "./db/chroma14"
upload_folder = "upload"
os.makedirs(upload_folder, exist_ok=True)

# Find which class prompt belongs to
tokenizer = AutoTokenizer.from_pretrained("bayartsogt/mongolian-gpt2")
tokenizer.pad_token = tokenizer.eos_token

generator = pipeline("text-generation", model="Ikhee10/khasbank_three_classifier_v13", tokenizer = tokenizer, device=0, num_beams=5)

translate_client = translate.Client()

def process_generated_text(text):
    matches = re.findall(r'<(.*?)>', text)
    ans = matches[1] if len(matches) > 0 else ''
    if ' ' in ans:
        ans = ans.split(' ')[0].strip()
    return ans
    
def generate_and_process(prompt):
    result = generator(prompt, max_length=32, pad_token_id=tokenizer.eos_token_id)
    generated_text = result[0]['generated_text']

    return process_generated_text(generated_text)


# Set up the embeddings
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

# Set up the vector store (Chroma)
try:
    vectorstore = Chroma(collection_name='v_db', persist_directory=chromadb, embedding_function=embeddings)
except Exception as e:
    print(f"Error Loading ChromaDB: {e}")

def chroma_retrieval_tool(query): 
    # Retrieve documents relevant to the query 
    query_mn = translate_client.translate(query, target_language="mn")["translatedText"]
    clas = generate_and_process('<s> bb: ' + query_mn)
    # TODO: noa
    if clas == "noa": 
        return "–ê—Å—É—É–ª—Ç –Ω—å —Ö–∞–º–∞–∞—Ä–∞–ª–≥“Ø–π –±–∞–π–Ω–∞. –•–∞—Ä–∏—É–ª–∞—Ö –±–æ–ª–æ–º–∂–≥“Ø–π. ”®”©—Ä –¥–∞—Ö–∏–∂ —Ö–∞–π—Ö, —Ö—ç—Ä—ç–≥–≥“Ø–π –∑–æ–≥—Å–æ–æ."

    docs = vectorstore.similarity_search(query_mn, k=5, filter={"type": clas}) 
    context = "\n".join([doc.page_content for doc in docs]) 
    return context

# Load model function
repo_id = "meta-llama/Meta-Llama-3-70B-Instruct"

def load_model():
    llm = HuggingFaceEndpoint(
        repo_id=repo_id,
        temperature=0.1,
        huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,
    )
    return llm

def get_agent_response(user_input):
    res = agent.run(user_input)
    res = translate_client.translate(res, target_language="mn")["translatedText"]
    return res

# Streamlit UI
# Apply custom CSS to lower the image
st.markdown("""
    <style>
        .lower-image {
            margin-top: 30px; /* Adjust this value to control the distance */
        }
    </style>
""", unsafe_allow_html=True)

# Create columns for image and text in one line
col1, col2 = st.columns([1, 8])  # Adjust the ratio (col1 for the image and col2 for the text)

with col1:
    # Apply the class to the image for custom margin
    st.markdown('<div class="lower-image">', unsafe_allow_html=True)
    st.image('./xacbank_logo-removebg-preview.png', width=80)  # Display image
    st.markdown('</div>', unsafe_allow_html=True)

with col2:
    st.header("Xacqa chatbot! üëã")  # Display header
    st.markdown("*IHH –±–∞–≥–∏–π–Ω –±“Ø—Ç—ç—ç—Å—ç–Ω —á–∞—Ç–±–æ—Ç–æ–¥ —Ç–∞–≤—Ç–∞–π –º–æ—Ä–∏–ª.*")

# Add a separator line between the text and input field
st.markdown("---")  # Horizontal line separator

# Title and input field for the user (input a bit lower)
query = st.text_input("–•—É—Ä—É—É–Ω—ã “Ø–∑“Ø“Ø—Ä—ç—ç—Ä –±–∞–Ω–∫–∞–∞ —É–¥–∏—Ä–¥!")  # Adjusted input field text

# Check if the "Send" button is clicked
if st.button("Send"):
    llm = load_model()

    template = """–î–æ–æ—Ä—Ö –∞—Å—É—É–ª—Ç–∞–Ω–¥ –Ω”©—Ö”©—Ä—Å–≥”©”©—Ä —Ö–∞—Ä–∏—É–ª–∞–∞—Ä–∞–π. –•–∞—Ä–∏—É–ª–∞—Ö–∞–¥ –¥–∞—Ä–∞–∞—Ö –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –∞—à–∏–≥–ª–∞–Ω–∞ —É—É. –•—ç—Ä—ç–≤ —Ç–∞ —Ö–∞—Ä–∏—É–ª—Ç–∞–∞ –º—ç–¥—ç—Ö–≥“Ø–π –±–æ–ª –º—ç–¥—ç—Ö–≥“Ø–π –≥—ç–∂ —Ö—ç–ª—ç—ç—Ä—ç–π, —Ö–∞—Ä–∏—É–ª—Ç –∑–æ—Ö–∏–æ—Ö –≥—ç–∂ –±“Ø“Ø –æ—Ä–æ–ª–¥–æ–æ—Ä–æ–π. –•–∞–º–≥–∏–π–Ω –∏—Ö–¥—ç—ç –≥—É—Ä–≤–∞–Ω ”©–≥“Ø“Ø–ª–±—ç—Ä –∞—à–∏–≥–ª–∞. –•–∞—Ä–∏—É–ª—Ç–∞–∞ –∞–ª—å –±–æ–ª–æ—Ö —Ç–æ–≤—á—Ö–æ–Ω –±–∏—á—ç—ç—Ä—ç–π. –•–∞—Ä–∏—É–ª—Ç—ã–Ω —Ç”©–≥—Å–≥”©–ª–¥ "–ê—Å—É—É—Å–∞–Ω–¥ –±–∞—è—Ä–ª–∞–ª–∞–∞!" –≥—ç–∂ “Ø—Ä–≥—ç–ª–∂ —Ö—ç–ª—ç—ç—Ä—ç–π.
        {context}
        –ê—Å—É—É–ª—Ç: {query}	
        –•—ç—Ä–≤—ç—ç –¥–∞—Ä–∞–∞—Ö–∏ –∞—Å—É—É–ª—Ç—É—É–¥–∏–π–≥ –∞—Å—É—É–≤–∞–ª —Ö–∞—Ä–∏—É–ª—Ç –≥—ç—Å—ç–Ω –∑–∞–∞–≤—Ä–∏–π–Ω –¥–∞–≥—É—É —Ö–∞—Ä–∏—É–ª:
        –ü–∏–Ω –∫–æ–¥ –º–∞—Ä—Ç—Å–∞–Ω    –•–∞—Ä–∏—É–ª—Ç:–î–∏–∂–∏—Ç–∞–ª –±–∞–Ω–∫–Ω—ã –∫–∞—Ä—Ç —Ü—ç—Å—ç—ç—Ä –±–æ–ª–æ–Ω ”©”©—Ä—Ç –æ–π—Ä—Ö–æ–Ω —Å–∞–ª–±–∞—Ä—Ç —à–∏–Ω—ç –ø–∏–Ω –∫–æ–¥ “Ø“Ø—Å–≥—ç—Ö –±–æ–ª–æ–º–∂—Ç–æ–π  –î–∏–∂–∏—Ç–∞–ª –±–∞–Ω–∫–∞–∞—Ä –∫–∞—Ä—Ç—ã–Ω –ø–∏–Ω –∫–æ–¥ —Å–æ–ª–∏—Ö –∑–∞–∞–≤–∞—Ä:https://www youtube com/watch?v=kCJS3hY3Wng
        –ò–Ω—Ç–µ—Ä–Ω—ç—Ç –ø–∏–Ω –∫–æ–¥ –∞–≤–∞—Ö  –•–∞—Ä–∏—É–ª—Ç: –¢–∞ –î–∏–∂–∏—Ç–∞–ª –±–∞–Ω–∫, –•–∞—Å–ë–∞–Ω–∫–Ω—ã –ê–¢–ú-—ç—ç—Å —é–º—É—É 18001888 –ª–∞–≤–ª–∞—Ö –¥—É–≥–∞–∞—Ä—Ç —Ö–æ–ª–±–æ–≥–¥–æ–Ω –∏–Ω—Ç–µ—Ä–Ω—ç—Ç –ø–∏–Ω –∫–æ–¥ –∞–≤–Ω–∞ —É—É  –ö–∞—Ä—Ç—ã–Ω –æ–Ω–ª–∞–π–Ω –≥“Ø–π–ª–≥—ç—ç–Ω–∏–π –ò-–ø–∏–Ω –∫–æ–¥ –∞–≤–∞—Ö –∑–∞–∞–≤–∞—Ä:https://www youtube com/watch?v=FxkzNptP-Sw
        –ö–∞—Ä—Ç —Ö–∞–∞–ª–≥–∞—Ö  –•–∞—Ä–∏—É–ª—Ç:–¢–∞ –î–∏–∂–∏—Ç–∞–ª –±–∞–Ω–∫–∞–∞—Ä –∫–∞—Ä—Ç–∞–∞ —Ç“Ø—Ä —Ö–∞–∞—Ö –±–æ–ª–æ–º–∂—Ç–æ–π  –ö–∞—Ä—Ç–∞–∞ —Ç“Ø—Ä —Ö–∞–∞—Ö –∑–∞–∞–≤–∞—Ä:https://www youtube com/watch?v=ZX9_JkjAhEM
        –ì“Ø–π–ª–≥—ç—ç–Ω–∏–π –ª–∏–º–∏—Ç  –•–∞—Ä–∏—É–ª—Ç:–ö–∞—Ä—Ç—ã–Ω —Ç”©—Ä–ª”©”©—Å —Ö–∞–º–∞–∞—Ä–∞–Ω ”©–¥—Ä–∏–π–Ω –≥“Ø–π–ª–≥—ç—ç–Ω–∏–π –ª–∏–º–∏—Ç ”©”©—Ä –±–∞–π–¥–∞–≥ 	
        –ö–∞—Ä—Ç –Ω—ç—ç–ª–≥—ç—Ö  –•–∞—Ä–∏—É–ª—Ç:–¢–∞ –≥—ç—ç–≥–¥“Ø“Ø–ª—Å—ç–Ω –∫–∞—Ä—Ç–∞–∞ –Ω—ç—ç–ª–≥—ç—Ö –±–æ–ª ”©”©—Ä—Ç –æ–π—Ä –±–∞–π—Ä–ª–∞—Ö —Å–∞–ª–±–∞—Ä—Ç —Ö–∞–Ω–¥–∞–∂ –Ω—ç—ç–ª–≥—ç–Ω—ç  –®–∏–Ω—ç—ç—Ä –∑–∞—Ö–∏–∞–ª—Å–∞–Ω –∫–∞—Ä—Ç–∞–∞ –∏–¥—ç–≤—Ö–∂“Ø“Ø–ª—ç—Ö –±–æ–ª 18001888 –ª–∞–≤–ª–∞—Ö –¥—É–≥–∞–∞—Ä—Ç —Ö–æ–ª–±–æ–≥–¥–æ–Ω–æ —É—É 
        –ö–∞—Ä—Ç –∑–∞—Ö–∏–∞–ª–∞—Ö  –•–∞—Ä–∏—É–ª—Ç:–¢–∞ XacBank Digital –∞–ø–ø–ª–∏–∫—ç–π—à–Ω —Ç–∞—Ç–∞–∂ –∞–≤–∞–Ω —ç—Å–≤—ç–ª –∏–Ω—Ç–µ—Ä–Ω—ç—Ç –±–∞–Ω–∫–∞–∞—Ä –∫–∞—Ä—Ç –∑–∞—Ö–∏–∞–ª–Ω–∞ —É—É 
        QPay-–¶–∞—Ö–∏–º —Ç“Ø—Ä–∏–π–≤—á –±“Ø—Ä—Ç–≥“Ø“Ø–ª—ç—Ö  –•–∞—Ä–∏—É–ª—Ç:–¢–∞ –≥–∞—Ä —É—Ç—Å–∞–Ω–¥–∞–∞ QPay Wallet –ê–ü–ü —Ç–∞—Ç–∞–∂, –±“Ø—Ä—Ç–≥—ç–ª “Ø“Ø—Å–≥—ç–Ω –∞—à–∏–≥–ª–∞—Ö –±–æ–ª–æ–º–∂—Ç–æ–π 	
        QPay-–¶–∞—Ö–∏–º —Ç“Ø—Ä–∏–π–≤—á –ö–∞—Ä—Ç –±“Ø—Ä—Ç–≥“Ø“Ø–ª—ç—Ö  –•–∞—Ä–∏—É–ª—Ç:–¢–∞ –ê–ü–ü-–∞–∞—Ä –Ω—ç–≤—Ç—ç—Ä—á –æ—Ä—Å–Ω—ã –¥–∞—Ä–∞–∞ –±–∞—Ä—É—É–Ω –±—É–ª–∞–Ω–¥ –±–∞–π—Ä–ª–∞—Ö + —Ç–æ–≤—á–∏–π–≥ —Å–æ–Ω–≥–æ–Ω –∫–∞—Ä—Ç—ã–Ω –º—ç–¥—ç—ç–ª–ª—ç—ç –±“Ø—Ä—Ç–≥“Ø“Ø–ª–Ω—ç “Ø“Ø 	
        """

    # Define the REACT_DOCSTORE tool 
    react_docstore_tool = Tool( 
        name="react-docstore", 
        description="–ú—ç–¥—ç—ç–ª—ç–ª –∞–≤–∞—Ö–¥–∞–∞ —ç—Ö–ª—ç—ç–¥ –±–æ–¥–¥–æ–≥ –¥–∞—Ä–∞–∞ –Ω—å “Ø–π–ª–¥—ç–ª —Ö–∏–π–¥—ç–≥ –∞–≥–µ–Ω—Ç. –≠–Ω—ç –∞–≥–µ–Ω—Ç –Ω—å –∞—Å—É—É–ª—Ç–∞–¥ —Ö–∞—Ä–∏—É–ª–∞—Ö—ã–Ω —Ç—É–ª–¥ —Ö–æ–ª–±–æ–≥–¥–æ—Ö –º—ç–¥—ç—ç–ª–ª–∏–π–≥ —Ö–∞–π—Ö –±–æ–ª–æ–º–∂—Ç–æ–π –º—ç–¥—ç—ç–ª–ª–∏–π–Ω —Å–∞–Ω–≥ –∞—à–∏–≥–ª–∞—Ö –±–æ–ª–æ–º–∂—Ç–æ–π.",
        func=chroma_retrieval_tool 
    )
    tools = load_tools(["google-serper", "llm-math"], llm=llm)
    tools.append(react_docstore_tool)

    # Initialize conversation memory
    memory = ConversationBufferMemory()

    agent = initialize_agent(
        tools, 
        llm, 
        agent="zero-shot-react-description", 
        memory=memory, 
        verbose=True, 
        prompt=template
    )
    # template_init = """–î–æ–æ—Ä—Ö –∞—Å—É—É–ª—Ç–∞–Ω–¥ —Ö–∞—Ä–∏—É–ª–∞–∞—Ä–∞–π. –ú—ç–¥—ç—ç–ª—ç–ª –∞–≤–∞—Ö–¥–∞–∞ —ç—Ö–ª—ç—ç–¥ –±–æ–¥–¥–æ–≥ –¥–∞—Ä–∞–∞ –Ω—å “Ø–π–ª–¥—ç–ª —Ö–∏–π–¥—ç–≥ –∞–≥–µ–Ω—Ç. –≠–Ω—ç –∞–≥–µ–Ω—Ç –Ω—å –∞—Å—É—É–ª—Ç–∞–¥ —Ö–∞—Ä–∏—É–ª–∞—Ö—ã–Ω —Ç—É–ª–¥ —Ö–æ–ª–±–æ–≥–¥–æ—Ö –º—ç–¥—ç—ç–ª–ª–∏–π–≥ —Ö–∞–π—Ö –±–æ–ª–æ–º–∂—Ç–æ–π –º—ç–¥—ç—ç–ª–ª–∏–π–Ω —Å–∞–Ω–≥ –∞—à–∏–≥–ª–∞—Ö –±–æ–ª–æ–º–∂—Ç–æ–π.
    #     –ê—Å—É—É–ª—Ç: {query}
    #     –•–∞—Ä–∏—É–ª—Ç: –•–∞—Ä–∏—É–ª–∞—Ö–∞–¥ –∞–ª—Ö–∞–º –∞–ª—Ö–º–∞–∞—Ä –±–æ–¥–æ–∂ “Ø–∑—å–µ.   
    # """
    # prompt = PromptTemplate.from_template(template_init)
    # formatted_prompt = prompt.format(query=query)

    # # Create the RetrievalQA chain with the formatted prompt and the model
    # qa = RetrievalQA.from_llm(llm, retriever=vectorstore.as_retriever())

    # If the query is provided, run the QA chain
    if query:
        # answer = qa.run(formatted_prompt)
        answer = agent.run(query)
        answer = translate_client.translate(answer, target_language="mn")["translatedText"]
        # Display the first part of the answer
        st.write(answer[:500])  # Display the first 500 characters

        # Check if the answer exceeds the displayed limit
        if len(answer) > 500:
            # Display "Continue" button
            if st.button("Continue"):
                # Display the rest of the answer
                st.write(answer[500:])